{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import autokeras as ak\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import reber\n",
    "RANDOM_STATE = 42\n",
    "PADDING_IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = reber.ReberGenerator(max_length=15)\n",
    "X, y = r.make_data(50000)\n",
    "_, word_len = X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.15, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.167342</td>\n",
       "      <td>4.001592</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>3.974617</td>\n",
       "      <td>5.467817</td>\n",
       "      <td>5.190667</td>\n",
       "      <td>4.334725</td>\n",
       "      <td>4.184042</td>\n",
       "      <td>3.561342</td>\n",
       "      <td>2.449292</td>\n",
       "      <td>1.665400</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>0.623558</td>\n",
       "      <td>0.370683</td>\n",
       "      <td>0.10195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.835490</td>\n",
       "      <td>1.082135</td>\n",
       "      <td>0.828863</td>\n",
       "      <td>1.079428</td>\n",
       "      <td>1.229692</td>\n",
       "      <td>1.455466</td>\n",
       "      <td>1.868470</td>\n",
       "      <td>1.651977</td>\n",
       "      <td>1.719170</td>\n",
       "      <td>2.098686</td>\n",
       "      <td>2.006475</td>\n",
       "      <td>1.727532</td>\n",
       "      <td>1.289127</td>\n",
       "      <td>1.075308</td>\n",
       "      <td>0.44220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  120000.000000  120000.000000  120000.000000  120000.000000   \n",
       "mean        1.167342       4.001592       1.165125       3.974617   \n",
       "std         0.835490       1.082135       0.828863       1.079428   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         1.000000       3.000000       1.000000       3.000000   \n",
       "50%         1.000000       4.000000       1.000000       3.000000   \n",
       "75%         1.000000       5.000000       1.000000       5.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  120000.000000  120000.000000  120000.000000  120000.000000   \n",
       "mean        5.467817       5.190667       4.334725       4.184042   \n",
       "std         1.229692       1.455466       1.868470       1.651977   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         5.000000       4.000000       2.000000       3.000000   \n",
       "50%         6.000000       6.000000       4.000000       4.000000   \n",
       "75%         7.000000       6.000000       6.000000       6.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                  8              9              10             11  \\\n",
       "count  120000.000000  120000.000000  120000.000000  120000.000000   \n",
       "mean        3.561342       2.449292       1.665400       1.104875   \n",
       "std         1.719170       2.098686       2.006475       1.727532   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         3.000000       2.000000       0.000000       0.000000   \n",
       "75%         5.000000       4.000000       3.000000       2.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                  12             13            14  \n",
       "count  120000.000000  120000.000000  120000.00000  \n",
       "mean        0.623558       0.370683       0.10195  \n",
       "std         1.289127       1.075308       0.44220  \n",
       "min         0.000000       0.000000       0.00000  \n",
       "25%         0.000000       0.000000       0.00000  \n",
       "50%         0.000000       0.000000       0.00000  \n",
       "75%         0.000000       0.000000       0.00000  \n",
       "max         7.000000       7.000000       7.00000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./auto_model/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./auto_model/tuner0.json\n",
      "Train for 1063 steps, validate for 266 steps\n",
      "Epoch 1/10\n",
      "1063/1063 - 82s - loss: 0.6699 - accuracy: 0.5347 - val_loss: 0.6551 - val_accuracy: 0.5585\n",
      "Epoch 2/10\n",
      "1063/1063 - 83s - loss: 0.6583 - accuracy: 0.5480 - val_loss: 0.6588 - val_accuracy: 0.5531\n",
      "Epoch 3/10\n",
      "1063/1063 - 70s - loss: 0.6597 - accuracy: 0.5448 - val_loss: 0.6587 - val_accuracy: 0.5529\n",
      "Epoch 4/10\n",
      "1063/1063 - 64s - loss: 0.6596 - accuracy: 0.5468 - val_loss: 0.6579 - val_accuracy: 0.5542\n",
      "Epoch 5/10\n",
      "1063/1063 - 64s - loss: 0.6593 - accuracy: 0.5468 - val_loss: 0.6585 - val_accuracy: 0.5533\n",
      "Epoch 6/10\n",
      "1063/1063 - 63s - loss: 0.6616 - accuracy: 0.5454 - val_loss: 0.6604 - val_accuracy: 0.5521\n",
      "Epoch 7/10\n",
      "1063/1063 - 61s - loss: 0.6539 - accuracy: 0.5556 - val_loss: 0.6428 - val_accuracy: 0.5751\n",
      "Epoch 8/10\n",
      "1063/1063 - 63s - loss: 0.6427 - accuracy: 0.5678 - val_loss: 0.6426 - val_accuracy: 0.5740\n",
      "Epoch 9/10\n",
      "1063/1063 - 61s - loss: 0.6545 - accuracy: 0.5614 - val_loss: 0.6944 - val_accuracy: 0.4941\n",
      "Epoch 10/10\n",
      "1063/1063 - 62s - loss: 0.6934 - accuracy: 0.5042 - val_loss: 0.6634 - val_accuracy: 0.5586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c07bf6c966b5bf1dc7068f5e8b444cb2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6425642671441674</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-embedding_1/embedding_dim: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-rnn_block_1/layer_type: lstm</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-rnn_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1063 steps, validate for 266 steps\n",
      "Epoch 1/10\n",
      "1063/1063 - 73s - loss: 0.6606 - accuracy: 0.5478 - val_loss: 0.5455 - val_accuracy: 0.7114\n",
      "Epoch 2/10\n",
      "1063/1063 - 66s - loss: 0.1213 - accuracy: 0.9622 - val_loss: 0.0533 - val_accuracy: 0.9858\n",
      "Epoch 3/10\n",
      "1063/1063 - 68s - loss: 0.0680 - accuracy: 0.9836 - val_loss: 0.0605 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "1063/1063 - 69s - loss: 0.0844 - accuracy: 0.9784 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "1063/1063 - 63s - loss: 0.0675 - accuracy: 0.9836 - val_loss: 0.0487 - val_accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "1063/1063 - 62s - loss: 0.0649 - accuracy: 0.9836 - val_loss: 0.0353 - val_accuracy: 0.9915\n",
      "Epoch 7/10\n",
      "1063/1063 - 63s - loss: 0.0458 - accuracy: 0.9885 - val_loss: 0.0431 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "1063/1063 - 62s - loss: 0.0333 - accuracy: 0.9929 - val_loss: 0.0275 - val_accuracy: 0.9946\n",
      "Epoch 9/10\n",
      "1063/1063 - 59s - loss: 0.0384 - accuracy: 0.9910 - val_loss: 0.0367 - val_accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "1063/1063 - 65s - loss: 0.0251 - accuracy: 0.9946 - val_loss: 0.0240 - val_accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 81879f3370923058197b352206446ef7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.024046585179123104</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-embedding_1/embedding_dim: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-rnn_block_1/layer_type: lstm</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-rnn_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 1329 steps, validate for 266 steps\n",
      "Epoch 1/10\n",
      "1329/1329 - 89s - loss: 0.6610 - accuracy: 0.5492 - val_loss: 0.6530 - val_accuracy: 0.5631\n",
      "Epoch 2/10\n",
      "1329/1329 - 77s - loss: 0.6515 - accuracy: 0.5590 - val_loss: 0.6461 - val_accuracy: 0.5701\n",
      "Epoch 3/10\n",
      "1329/1329 - 82s - loss: 0.6486 - accuracy: 0.5625 - val_loss: 0.6467 - val_accuracy: 0.5686\n",
      "Epoch 4/10\n",
      "1329/1329 - 78s - loss: 0.2888 - accuracy: 0.8532 - val_loss: 0.1026 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "1329/1329 - 77s - loss: 0.0819 - accuracy: 0.9797 - val_loss: 0.0889 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "1329/1329 - 77s - loss: 0.0654 - accuracy: 0.9842 - val_loss: 0.0418 - val_accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "1329/1329 - 76s - loss: 0.0536 - accuracy: 0.9873 - val_loss: 0.0388 - val_accuracy: 0.9922\n",
      "Epoch 8/10\n",
      "1329/1329 - 83s - loss: 0.0350 - accuracy: 0.9921 - val_loss: 0.0255 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "1329/1329 - 81s - loss: 0.0332 - accuracy: 0.9921 - val_loss: 0.0108 - val_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "1329/1329 - 81s - loss: 0.0189 - accuracy: 0.9955 - val_loss: 0.0088 - val_accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "num_features = len(r._reber_letters) + 1 # include padding token\n",
    "\n",
    "input_node = ak.Input()\n",
    "output_node = ak.Embedding(# TODO: how to mask in the embedding\n",
    "    max_features=num_features,\n",
    "    pretraining='random',\n",
    "    dropout_rate=0\n",
    ")(input_node)\n",
    "output_node = ak.RNNBlock(\n",
    "    bidirectional=False,\n",
    "#     num_layers=1, # let it search the space\n",
    "#     layer_type='gru'\n",
    ")(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node,\n",
    "    outputs=output_node,\n",
    "    max_trials=8\n",
    ")\n",
    "# TODO: increase number of epochs\n",
    "clf.fit(X_train.to_numpy(), y_train.to_numpy(), verbose=2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - ETA: 3:33 - loss: 0.0016 - accuracy: 1.00 - ETA: 31s - loss: 0.0021 - accuracy: 1.0000 - ETA: 20s - loss: 0.0080 - accuracy: 0.997 - ETA: 17s - loss: 0.0177 - accuracy: 0.995 - ETA: 13s - loss: 0.0214 - accuracy: 0.994 - ETA: 12s - loss: 0.0186 - accuracy: 0.995 - ETA: 11s - loss: 0.0166 - accuracy: 0.996 - ETA: 10s - loss: 0.0151 - accuracy: 0.996 - ETA: 10s - loss: 0.0147 - accuracy: 0.996 - ETA: 9s - loss: 0.0138 - accuracy: 0.996 - ETA: 9s - loss: 0.0128 - accuracy: 0.99 - ETA: 8s - loss: 0.0118 - accuracy: 0.99 - ETA: 8s - loss: 0.0111 - accuracy: 0.99 - ETA: 7s - loss: 0.0105 - accuracy: 0.99 - ETA: 7s - loss: 0.0128 - accuracy: 0.99 - ETA: 7s - loss: 0.0124 - accuracy: 0.99 - ETA: 6s - loss: 0.0119 - accuracy: 0.99 - ETA: 6s - loss: 0.0113 - accuracy: 0.99 - ETA: 6s - loss: 0.0107 - accuracy: 0.99 - ETA: 5s - loss: 0.0105 - accuracy: 0.99 - ETA: 5s - loss: 0.0101 - accuracy: 0.99 - ETA: 5s - loss: 0.0142 - accuracy: 0.99 - ETA: 5s - loss: 0.0135 - accuracy: 0.99 - ETA: 4s - loss: 0.0140 - accuracy: 0.99 - ETA: 4s - loss: 0.0156 - accuracy: 0.99 - ETA: 4s - loss: 0.0150 - accuracy: 0.99 - ETA: 4s - loss: 0.0163 - accuracy: 0.99 - ETA: 3s - loss: 0.0157 - accuracy: 0.99 - ETA: 3s - loss: 0.0152 - accuracy: 0.99 - ETA: 3s - loss: 0.0149 - accuracy: 0.99 - ETA: 3s - loss: 0.0145 - accuracy: 0.99 - ETA: 3s - loss: 0.0143 - accuracy: 0.99 - ETA: 3s - loss: 0.0141 - accuracy: 0.99 - ETA: 3s - loss: 0.0150 - accuracy: 0.99 - ETA: 3s - loss: 0.0146 - accuracy: 0.99 - ETA: 3s - loss: 0.0143 - accuracy: 0.99 - ETA: 3s - loss: 0.0140 - accuracy: 0.99 - ETA: 3s - loss: 0.0157 - accuracy: 0.99 - ETA: 2s - loss: 0.0155 - accuracy: 0.99 - ETA: 2s - loss: 0.0152 - accuracy: 0.99 - ETA: 2s - loss: 0.0148 - accuracy: 0.99 - ETA: 2s - loss: 0.0145 - accuracy: 0.99 - ETA: 2s - loss: 0.0142 - accuracy: 0.99 - ETA: 2s - loss: 0.0139 - accuracy: 0.99 - ETA: 2s - loss: 0.0148 - accuracy: 0.99 - ETA: 2s - loss: 0.0158 - accuracy: 0.99 - ETA: 2s - loss: 0.0155 - accuracy: 0.99 - ETA: 2s - loss: 0.0152 - accuracy: 0.99 - ETA: 1s - loss: 0.0155 - accuracy: 0.99 - ETA: 1s - loss: 0.0153 - accuracy: 0.99 - ETA: 1s - loss: 0.0152 - accuracy: 0.99 - ETA: 1s - loss: 0.0150 - accuracy: 0.99 - ETA: 1s - loss: 0.0148 - accuracy: 0.99 - ETA: 1s - loss: 0.0147 - accuracy: 0.99 - ETA: 1s - loss: 0.0144 - accuracy: 0.99 - ETA: 1s - loss: 0.0141 - accuracy: 0.99 - ETA: 1s - loss: 0.0139 - accuracy: 0.99 - ETA: 1s - loss: 0.0138 - accuracy: 0.99 - ETA: 1s - loss: 0.0137 - accuracy: 0.99 - ETA: 1s - loss: 0.0145 - accuracy: 0.99 - ETA: 1s - loss: 0.0143 - accuracy: 0.99 - ETA: 1s - loss: 0.0141 - accuracy: 0.99 - ETA: 1s - loss: 0.0139 - accuracy: 0.99 - ETA: 0s - loss: 0.0137 - accuracy: 0.99 - ETA: 0s - loss: 0.0135 - accuracy: 0.99 - ETA: 0s - loss: 0.0136 - accuracy: 0.99 - ETA: 0s - loss: 0.0133 - accuracy: 0.99 - ETA: 0s - loss: 0.0142 - accuracy: 0.99 - ETA: 0s - loss: 0.0143 - accuracy: 0.99 - ETA: 0s - loss: 0.0141 - accuracy: 0.99 - ETA: 0s - loss: 0.0140 - accuracy: 0.99 - ETA: 0s - loss: 0.0139 - accuracy: 0.99 - ETA: 0s - loss: 0.0146 - accuracy: 0.99 - ETA: 0s - loss: 0.0149 - accuracy: 0.99 - 5s 22ms/step - loss: 0.0148 - accuracy: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.014766630970506353, 0.9964]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(X_test.to_numpy(), y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model = clf.export_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('99_test_acc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/2\n",
      "80000/80000 [==============================] - 17s 217us/step - loss: 0.6903 - accuracy: 0.5657 - val_loss: 0.6851 - val_accuracy: 0.4983\n",
      "Epoch 2/2\n",
      "80000/80000 [==============================] - 18s 224us/step - loss: 0.6665 - accuracy: 0.5379 - val_loss: 0.6395 - val_accuracy: 0.6458\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=1,\n",
    "    batch_size=5000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97984904]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strs = [\n",
    "#     \"BPBTSSXXVVEPE\", # true reber\n",
    "#     \"BPBTSSSSXXVPXTTTVPSETE\", # second and second to last not the same, but reber inbetween\n",
    "#     \"BPBPTTTTTVPBTTTTVPSEPT\", # second and second to last the same, but not reber in middle\n",
    "#     \"BBBBBBBBBBB\",\n",
    "#     \"XXXXXXXXXXXXXX\",\n",
    "#     \"TTTTTTTTTTTTTTTTTTT\"\n",
    "# ]\n",
    "x = np.array([\n",
    "        r.encode_as_padded_ints(s) for s in ['BPBTSSXXVVEPPE']\n",
    "    ])\n",
    "dataset = clf._process_x(x, False)\n",
    "dataset = dataset.batch(6)\n",
    "model = clf.tuner.get_best_model()\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, XXXXXXXXXX is not in the reber grammar, and yet the model predicted with 98.6% certainty that it was. This means that I need to make my examples of non-reber much more random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## autokeras\n",
    "embedding_vector_length = len(r._reber_letters) # TODO: what should this be?\n",
    "num_neurons = 60\n",
    "model = Sequential()\n",
    "Embedding\n",
    "model.add(\n",
    "    Embedding(\n",
    "        embedding_vector_length + 1,\n",
    "        embedding_vector_length,\n",
    "        input_length=word_len,\n",
    "        mask_zero=True\n",
    "    )\n",
    ")\n",
    "model.add(LSTM(num_neurons))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reber-grammar-lstm",
   "language": "python",
   "name": "reber-grammar-lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
