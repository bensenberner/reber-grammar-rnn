{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import reber\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding, Activation\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "PADDING_IDX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data generator creates four different types of strings: \"valid\" embedded reber strings, and then three different types of invalid embedded reber strings. See reber.py for a full description of each type of invalid string. For now, we don't bother to differentiate between the different types of invalid; we give them all the same \"0\" label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = reber.ReberGenerator(max_length=15)\n",
    "X, y = r.make_data(\n",
    "    50000,\n",
    "    valid=50,\n",
    "    symmetry_disturbed=40,\n",
    "    random=5,\n",
    "    perturbed=5,  # perturbed is probably too low, given later testing\n",
    ")\n",
    "_, word_len = X.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've represented the strings by ordinal numbers. Rather than representing the character's place in the English alphabet, they represent the position in *Reber* alphabet (which only consists of BEPSTVX). 0 is the padding character, so B=1, E=2, etc.\n",
    "If you look below, you can see that the minimum length for a reber string is 8 characters. At position 8 (starting from 0), the first instance of the 0 padding character appears.\n",
    "You can also see that, because of the \"monte carlo\" esque way in which I generated the strings (by walking through the grammar until it reaches the end), that lengths of the strings begins to drop off after 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "      <td>120000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.167342</td>\n",
       "      <td>4.001592</td>\n",
       "      <td>1.165125</td>\n",
       "      <td>3.974617</td>\n",
       "      <td>5.467817</td>\n",
       "      <td>5.190667</td>\n",
       "      <td>4.334725</td>\n",
       "      <td>4.184042</td>\n",
       "      <td>3.561342</td>\n",
       "      <td>2.449292</td>\n",
       "      <td>1.665400</td>\n",
       "      <td>1.104875</td>\n",
       "      <td>0.623558</td>\n",
       "      <td>0.370683</td>\n",
       "      <td>0.10195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.835490</td>\n",
       "      <td>1.082135</td>\n",
       "      <td>0.828863</td>\n",
       "      <td>1.079428</td>\n",
       "      <td>1.229692</td>\n",
       "      <td>1.455466</td>\n",
       "      <td>1.868470</td>\n",
       "      <td>1.651977</td>\n",
       "      <td>1.719170</td>\n",
       "      <td>2.098686</td>\n",
       "      <td>2.006475</td>\n",
       "      <td>1.727532</td>\n",
       "      <td>1.289127</td>\n",
       "      <td>1.075308</td>\n",
       "      <td>0.44220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  120000.000000  120000.000000  120000.000000  120000.000000   \n",
       "mean        1.167342       4.001592       1.165125       3.974617   \n",
       "std         0.835490       1.082135       0.828863       1.079428   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         1.000000       3.000000       1.000000       3.000000   \n",
       "50%         1.000000       4.000000       1.000000       3.000000   \n",
       "75%         1.000000       5.000000       1.000000       5.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  120000.000000  120000.000000  120000.000000  120000.000000   \n",
       "mean        5.467817       5.190667       4.334725       4.184042   \n",
       "std         1.229692       1.455466       1.868470       1.651977   \n",
       "min         1.000000       1.000000       1.000000       1.000000   \n",
       "25%         5.000000       4.000000       2.000000       3.000000   \n",
       "50%         6.000000       6.000000       4.000000       4.000000   \n",
       "75%         7.000000       6.000000       6.000000       6.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                  8              9              10             11  \\\n",
       "count  120000.000000  120000.000000  120000.000000  120000.000000   \n",
       "mean        3.561342       2.449292       1.665400       1.104875   \n",
       "std         1.719170       2.098686       2.006475       1.727532   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         3.000000       2.000000       0.000000       0.000000   \n",
       "75%         5.000000       4.000000       3.000000       2.000000   \n",
       "max         7.000000       7.000000       7.000000       7.000000   \n",
       "\n",
       "                  12             13            14  \n",
       "count  120000.000000  120000.000000  120000.00000  \n",
       "mean        0.623558       0.370683       0.10195  \n",
       "std         1.289127       1.075308       0.44220  \n",
       "min         0.000000       0.000000       0.00000  \n",
       "25%         0.000000       0.000000       0.00000  \n",
       "50%         0.000000       0.000000       0.00000  \n",
       "75%         0.000000       0.000000       0.00000  \n",
       "max         7.000000       7.000000       7.00000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to use autokeras to create a model to do the classification for me.\n",
    "First, it embeds my ordinal vectors into some higher dimensional space (which it learns)\n",
    "Then, it automatically determines how many layers of RNN it needs to do the classification.\n",
    "You can see that it tries multiple different hyperparameters (presumably using some sort of bayesian search methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./auto_model/oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from ./auto_model/tuner0.json\n",
      "Train for 1063 steps, validate for 266 steps\n",
      "Epoch 1/10\n",
      "1063/1063 - 82s - loss: 0.6699 - accuracy: 0.5347 - val_loss: 0.6551 - val_accuracy: 0.5585\n",
      "Epoch 2/10\n",
      "1063/1063 - 83s - loss: 0.6583 - accuracy: 0.5480 - val_loss: 0.6588 - val_accuracy: 0.5531\n",
      "Epoch 3/10\n",
      "1063/1063 - 70s - loss: 0.6597 - accuracy: 0.5448 - val_loss: 0.6587 - val_accuracy: 0.5529\n",
      "Epoch 4/10\n",
      "1063/1063 - 64s - loss: 0.6596 - accuracy: 0.5468 - val_loss: 0.6579 - val_accuracy: 0.5542\n",
      "Epoch 5/10\n",
      "1063/1063 - 64s - loss: 0.6593 - accuracy: 0.5468 - val_loss: 0.6585 - val_accuracy: 0.5533\n",
      "Epoch 6/10\n",
      "1063/1063 - 63s - loss: 0.6616 - accuracy: 0.5454 - val_loss: 0.6604 - val_accuracy: 0.5521\n",
      "Epoch 7/10\n",
      "1063/1063 - 61s - loss: 0.6539 - accuracy: 0.5556 - val_loss: 0.6428 - val_accuracy: 0.5751\n",
      "Epoch 8/10\n",
      "1063/1063 - 63s - loss: 0.6427 - accuracy: 0.5678 - val_loss: 0.6426 - val_accuracy: 0.5740\n",
      "Epoch 9/10\n",
      "1063/1063 - 61s - loss: 0.6545 - accuracy: 0.5614 - val_loss: 0.6944 - val_accuracy: 0.4941\n",
      "Epoch 10/10\n",
      "1063/1063 - 62s - loss: 0.6934 - accuracy: 0.5042 - val_loss: 0.6634 - val_accuracy: 0.5586\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c07bf6c966b5bf1dc7068f5e8b444cb2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.6425642671441674</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-embedding_1/embedding_dim: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-rnn_block_1/layer_type: lstm</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-rnn_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1063 steps, validate for 266 steps\n",
      "Epoch 1/10\n",
      "1063/1063 - 73s - loss: 0.6606 - accuracy: 0.5478 - val_loss: 0.5455 - val_accuracy: 0.7114\n",
      "Epoch 2/10\n",
      "1063/1063 - 66s - loss: 0.1213 - accuracy: 0.9622 - val_loss: 0.0533 - val_accuracy: 0.9858\n",
      "Epoch 3/10\n",
      "1063/1063 - 68s - loss: 0.0680 - accuracy: 0.9836 - val_loss: 0.0605 - val_accuracy: 0.9852\n",
      "Epoch 4/10\n",
      "1063/1063 - 69s - loss: 0.0844 - accuracy: 0.9784 - val_loss: 0.0515 - val_accuracy: 0.9885\n",
      "Epoch 5/10\n",
      "1063/1063 - 63s - loss: 0.0675 - accuracy: 0.9836 - val_loss: 0.0487 - val_accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "1063/1063 - 62s - loss: 0.0649 - accuracy: 0.9836 - val_loss: 0.0353 - val_accuracy: 0.9915\n",
      "Epoch 7/10\n",
      "1063/1063 - 63s - loss: 0.0458 - accuracy: 0.9885 - val_loss: 0.0431 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "1063/1063 - 62s - loss: 0.0333 - accuracy: 0.9929 - val_loss: 0.0275 - val_accuracy: 0.9946\n",
      "Epoch 9/10\n",
      "1063/1063 - 59s - loss: 0.0384 - accuracy: 0.9910 - val_loss: 0.0367 - val_accuracy: 0.9905\n",
      "Epoch 10/10\n",
      "1063/1063 - 65s - loss: 0.0251 - accuracy: 0.9946 - val_loss: 0.0240 - val_accuracy: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 81879f3370923058197b352206446ef7</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.024046585179123104</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-classification_head_1/dropout_rate: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/dropout_rate: 0.25</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-embedding_1/embedding_dim: 128</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-embedding_1/pretraining: none</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-optimizer: adam</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-rnn_block_1/layer_type: lstm</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-rnn_block_1/num_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "Train for 1329 steps, validate for 266 steps\n",
      "Epoch 1/10\n",
      "1329/1329 - 89s - loss: 0.6610 - accuracy: 0.5492 - val_loss: 0.6530 - val_accuracy: 0.5631\n",
      "Epoch 2/10\n",
      "1329/1329 - 77s - loss: 0.6515 - accuracy: 0.5590 - val_loss: 0.6461 - val_accuracy: 0.5701\n",
      "Epoch 3/10\n",
      "1329/1329 - 82s - loss: 0.6486 - accuracy: 0.5625 - val_loss: 0.6467 - val_accuracy: 0.5686\n",
      "Epoch 4/10\n",
      "1329/1329 - 78s - loss: 0.2888 - accuracy: 0.8532 - val_loss: 0.1026 - val_accuracy: 0.9739\n",
      "Epoch 5/10\n",
      "1329/1329 - 77s - loss: 0.0819 - accuracy: 0.9797 - val_loss: 0.0889 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "1329/1329 - 77s - loss: 0.0654 - accuracy: 0.9842 - val_loss: 0.0418 - val_accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "1329/1329 - 76s - loss: 0.0536 - accuracy: 0.9873 - val_loss: 0.0388 - val_accuracy: 0.9922\n",
      "Epoch 8/10\n",
      "1329/1329 - 83s - loss: 0.0350 - accuracy: 0.9921 - val_loss: 0.0255 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "1329/1329 - 81s - loss: 0.0332 - accuracy: 0.9921 - val_loss: 0.0108 - val_accuracy: 0.9978\n",
      "Epoch 10/10\n",
      "1329/1329 - 81s - loss: 0.0189 - accuracy: 0.9955 - val_loss: 0.0088 - val_accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "num_features = len(r._reber_letters) + 1  # include padding token\n",
    "\n",
    "input_node = ak.Input()\n",
    "output_node = ak.Embedding(\n",
    "    max_features=num_features, pretraining=\"random\", dropout_rate=0\n",
    ")(input_node)\n",
    "output_node = ak.RNNBlock(bidirectional=False, layer_type=\"lstm\")(output_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(inputs=input_node, outputs=output_node, max_trials=8)\n",
    "clf.fit(X_train.to_numpy(), y_train.to_numpy(), verbose=2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.export_model()\n",
    "model.save('test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9877208e-01],\n",
       "       [2.0613670e-04],\n",
       "       [9.7213304e-01]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(\n",
    "    [\n",
    "        r.encode_as_padded_ints(s)\n",
    "        for s in [\"BPBTSSXXVVEPE\", \"BPBTSSXXVVEPPE\", \"BPBTSSXXVVEPEE\"]\n",
    "    ]\n",
    ")\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model recognizes that two Ps cannot occur together near the end of the string, but not that two Es cannot occur together. Data needs some augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reber-grammar-rnn",
   "language": "python",
   "name": "reber-grammar-rnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
